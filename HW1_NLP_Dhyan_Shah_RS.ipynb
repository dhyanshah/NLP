{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSDS  7337-404 - Natural Language Processing ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework1 ###\n",
    "**Shah Dhyan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Question 1 ***\n",
    "\n",
    "****Python Installed****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Question 2 ***\n",
    "\n",
    "****Lexical Diversity Scoring Routine****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words_from_text(text1):\n",
    "    words = word_tokenize(text1)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return ' '.join([w for w in words if not w in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lexical Diversity Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07406285585022564"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    return float(len(set(text))) / len(text)\n",
    "lexical_diversity(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04826383002768831"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    return float(len(set(text))) / len(text)\n",
    "lexical_diversity(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    return float(len(set(text))) / len(text)\n",
    "lexical_diversity(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06617622515804722"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    return float(len(set(text))) / len(text)\n",
    "lexical_diversity(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13477005109975562"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    return float(len(set(text))) / len(text)\n",
    "lexical_diversity(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1276595744680851"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    return float(len(set(text))) / len(text)\n",
    "lexical_diversity(text6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12324685128531129"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    return float(len(set(text))) / len(text)\n",
    "lexical_diversity(text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22765564002465585"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    return float(len(set(text))) / len(text)\n",
    "lexical_diversity(text8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0983485761345412"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    return float(len(set(text))) / len(text)\n",
    "lexical_diversity(text9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Question 3 ***\n",
    "\n",
    "**Get Gutenberg Text : Graded Readers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_by_grade_level = {\n",
    "    'first': 'http://www.gutenberg.org/ebooks/14640.txt.utf-8',\n",
    "    'third': 'http://www.gutenberg.org/ebooks/14766.txt.utf-8',\n",
    "    'fifth': 'http://www.gutenberg.org/ebooks/15040.txt.utf-8'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Diversity Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_diversity 0.0013633158348350701 | level:first\n",
      "text_diversity 0.0005173951828724353 | level:third\n",
      "text_diversity 0.00014538990101921624 | level:fifth\n"
     ]
    }
   ],
   "source": [
    "grade_books_by_url = {}\n",
    "def get_book_text(url):\n",
    "    if url in grade_books_by_url:\n",
    "        return grade_books_by_url[url]\n",
    "    text = requests.get(url).text\n",
    "    grade_books_by_url[url] = text\n",
    "    return text\n",
    "\n",
    "def get_diversity_all_texts():\n",
    "    for text_level in text_by_grade_level:\n",
    "        url = text_by_grade_level[text_level]\n",
    "        text = get_book_text(url)\n",
    "        diversity = lexical_diversity(text)\n",
    "        print('text_diversity {} | level:{}'.format(diversity, text_level))\n",
    "get_diversity_all_texts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Question 4 ***\n",
    "\n",
    "**Vocabulary Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size 87 | level:first\n",
      "vocabulary size 87 | level:third\n",
      "vocabulary size 88 | level:fifth\n"
     ]
    }
   ],
   "source": [
    "def get_vocabulary_size_all_texts():\n",
    "    for text_level in text_by_grade_level:\n",
    "        url = text_by_grade_level[text_level]\n",
    "        text = get_book_text(url)\n",
    "        unique_characters = set(text)\n",
    "        vocabulary_size = len(unique_characters)\n",
    "        print('vocabulary size {} | level:{}'.format(vocabulary_size, text_level))\n",
    "get_vocabulary_size_all_texts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Question 5 ***\n",
    "\n",
    "**Comparision of Lexical Diversity and Vocabulary Size**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lexical diversity basically refers to the variety of words used in any text. If you have a set of text in which one set uses repetative words versus the other set that uses different words from vocabulary. If you then compare the text of both sets, most likely the second set will be very difficult to interpret by a machine. Example: meditation which can be interpreted by words like thinking, musing, focusing or contemplation. Whereas, using focusing and thinking over and over in the text and compare the two sets, naturally the earlier in the example can be said to have more \"lexical diversity\" than the other set. If we look at the result of our sample Gutenberg Text, both the VC and LD are small and seem to have some relationship between however LD can be more impactful measure to the level of text difficulty/reading level if we are to consider both measure together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
